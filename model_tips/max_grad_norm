gradnorm是一种优化方法，在多任务学习（Multi-Task Learning）中，
解决
1. 不同任务loss梯度的量级（magnitude）不同，造成有的task在梯度反向传播中占主导地位，模型过分学习该任务而忽视其它任务；
2. 不同任务收敛速度不一致；